{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2174ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # type: ignore[attr-defined]\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor # type: ignore[attr-defined]\n",
    "from causal_wrapper import load_causal_whisper\n",
    "from utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fdf2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"openai/whisper-base\"\n",
    "DEVICE = \"cuda:6\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34669916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CausalWhisperForConditionalGeneration were not initialized from the model checkpoint at openai/whisper-base and are newly initialized: ['model.encoder.causal_mask']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# The model weights are loaded properly, so when you give it inf (=1500) look ahead, it should give you the same output as the original model.\n",
    "\n",
    "my_model = load_causal_whisper(MODEL_ID, for_conditional=True)\n",
    "my_model.model.encoder.causal_mask = my_model.model.encoder._create_lookahead_mask(1500, 1500)\n",
    "my_model.to(DEVICE)\n",
    "\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID)\n",
    "whisper_model.to(DEVICE)\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf181338",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = prepare_data(max_shards=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c132adba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:6')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.model.encoder.causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cd30f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(\n",
      "        self,\n",
      "        hidden_states: torch.Tensor,\n",
      "        attention_mask: torch.Tensor,\n",
      "        layer_head_mask: torch.Tensor,\n",
      "        output_attentions: bool = False,\n",
      "    ) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
      "            attention_mask (`torch.FloatTensor`): attention mask of size\n",
      "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
      "            layer_head_mask (`torch.FloatTensor`): mask for attention heads in a given layer of size\n",
      "                `(encoder_attention_heads,)`.\n",
      "            output_attentions (`bool`, *optional*):\n",
      "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
      "                returned tensors for more detail.\n",
      "        \"\"\"\n",
      "        residual = hidden_states\n",
      "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
      "        hidden_states, attn_weights, _ = self.self_attn(\n",
      "            hidden_states=hidden_states,\n",
      "            attention_mask=attention_mask,\n",
      "            layer_head_mask=layer_head_mask,\n",
      "            output_attentions=output_attentions,\n",
      "        )\n",
      "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
      "        hidden_states = residual + hidden_states\n",
      "\n",
      "        residual = hidden_states\n",
      "        hidden_states = self.final_layer_norm(hidden_states)\n",
      "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
      "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
      "        hidden_states = self.fc2(hidden_states)\n",
      "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
      "        hidden_states = residual + hidden_states\n",
      "\n",
      "        if hidden_states.dtype == torch.float16:\n",
      "            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
      "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
      "\n",
      "        outputs = (hidden_states,)\n",
      "\n",
      "        if output_attentions:\n",
      "            outputs += (attn_weights,)\n",
      "\n",
      "        return outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(my_model.model.encoder.layers[0].forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "477a1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.61093807220459\n",
      "3.61093807220459\n",
      "\n",
      "\n",
      "torch.Size([1, 1500, 512])\n",
      "torch.Size([1, 1500, 512])\n",
      "diff tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:6')\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    sample = ds[i]                                            # type: ignore[attr-defined]\n",
    "    audio = torch.from_numpy(sample[\"mp3\"][\"array\"]).float()  # type: ignore[attr-defined]\n",
    "    text = sample[\"json\"][\"text\"]                             # type: ignore[attr-defined]\n",
    "    \n",
    "    labels = torch.tensor(processor.tokenizer(text, add_special_tokens=False).input_ids).unsqueeze(0)  # type: ignore[attr-defined]\n",
    "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")  \n",
    "    \n",
    "    labels = labels.to(DEVICE)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        my_latents = my_model.model.encoder(\n",
    "            inputs.input_features \n",
    "            )\n",
    "        \n",
    "        my_outputs = my_model(\n",
    "            inputs.input_features,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        whisper_latents = whisper_model.model.encoder(\n",
    "            inputs.input_features\n",
    "            )\n",
    "        \n",
    "        whisper_outputs = whisper_model(\n",
    "            inputs.input_features,\n",
    "            labels=labels\n",
    "            )\n",
    "        \n",
    "        \n",
    "    my_results = processor.batch_decode(my_outputs.logits.argmax(dim=-1), skip_special_tokens=True)[0]  # type: ignore[attr-defined]\n",
    "    whisper_results = processor.batch_decode(whisper_outputs.logits.argmax(dim=-1), skip_special_tokens=True)[0]  # type: ignore[attr-defined]\n",
    "        \n",
    "    print(my_outputs.loss.item())\n",
    "    print(whisper_outputs.loss.item())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(my_latents.last_hidden_state.shape)\n",
    "    print(whisper_latents.last_hidden_state.shape)\n",
    "    \n",
    "    print(f\"diff {my_latents.last_hidden_state[0][0] - whisper_latents.last_hidden_state[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cc8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
