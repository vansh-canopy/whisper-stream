{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2174ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # type: ignore[attr-defined]\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor # type: ignore[attr-defined]\n",
    "from causal_wrapper import load_causal_whisper\n",
    "from utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdf2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"openai/whisper-base\"\n",
    "DEVICE = \"cuda:6\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34669916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model weights are loaded properly, so when you give it inf (=1500) look ahead, it should give you the same output as the original model.\n",
    "\n",
    "my_model = load_causal_whisper(MODEL_ID, for_conditional=True)\n",
    "my_model.model.encoder.causal_mask = my_model.model.encoder._create_lookahead_mask(1500, 1500)\n",
    "my_model.to(DEVICE)\n",
    "\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID)\n",
    "whisper_model.to(DEVICE)\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf181338",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = prepare_data(max_shards=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.model.encoder.causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd30f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(my_model.model.encoder.layers[0].forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    sample = ds[i]                                            # type: ignore[attr-defined]\n",
    "    audio = torch.from_numpy(sample[\"mp3\"][\"array\"]).float()  # type: ignore[attr-defined]\n",
    "    text = sample[\"json\"][\"text\"]                             # type: ignore[attr-defined]\n",
    "    \n",
    "    labels = torch.tensor(processor.tokenizer(text, add_special_tokens=False).input_ids).unsqueeze(0)  # type: ignore[attr-defined]\n",
    "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")  \n",
    "    \n",
    "    labels = labels.to(DEVICE)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        my_latents = my_model.model.encoder(\n",
    "            inputs.input_features \n",
    "            )\n",
    "        \n",
    "        my_outputs = my_model(\n",
    "            inputs.input_features,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        whisper_latents = whisper_model.model.encoder(\n",
    "            inputs.input_features\n",
    "            )\n",
    "        \n",
    "        whisper_outputs = whisper_model(\n",
    "            inputs.input_features,\n",
    "            labels=labels\n",
    "            )\n",
    "        \n",
    "        \n",
    "    my_results = processor.batch_decode(my_outputs.logits.argmax(dim=-1), skip_special_tokens=True)[0]  # type: ignore[attr-defined]\n",
    "    whisper_results = processor.batch_decode(whisper_outputs.logits.argmax(dim=-1), skip_special_tokens=True)[0]  # type: ignore[attr-defined]\n",
    "        \n",
    "    print(my_outputs.loss.item())\n",
    "    print(whisper_outputs.loss.item())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(my_latents.last_hidden_state.shape)\n",
    "    print(whisper_latents.last_hidden_state.shape)\n",
    "    \n",
    "    print(f\"diff {my_latents.last_hidden_state[0][0] - whisper_latents.last_hidden_state[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cc8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
