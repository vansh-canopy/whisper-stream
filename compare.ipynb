{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712ceb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vansh/whisper-stream/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "             # type: ignore\n",
    "import torch\n",
    "import torchaudio\n",
    "from utils import load_model, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c10d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "model, processor = load_model(causal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d588a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17909930"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "ds = prepare_data()     \n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcd248e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:  You can help my mother and you- No. You didn't leave a bad situation back home to get caught up in another one here. What happened to you, Los Angeles?\n",
      "Transcription:  You can help my mother in need. No. You didn't leave a bad situation back home to get caught up in another one here. What happened to you, Los Angeles?\n",
      "\n",
      "\n",
      "Ground truth:  Honda's gone, 20 squads done. X is gonna split us up and put us on different squads. The team's come and go, but 20 squad, can't believe it's ending.\n",
      "Transcription:  Honda's gone, the 20 squats done. X is gonna split us up and put us on different squats. The team's coming, go, but 20 squats. Can't believe it's ending.\n",
      "\n",
      "\n",
      "Ground truth:  Alright. TCB! Sure you don't want some.\n",
      "Transcription:  All right, TCB. Sure you don't want some.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Running inference...\")\n",
    "for i in range(3):\n",
    "    sample = ds[i]                                           # type: ignore[attr-defined]\n",
    "    audio_wav = sample[\"mp3\"][\"array\"]                       # type: ignore[attr-defined]\n",
    "    audio_array = torch.from_numpy(audio_wav).to(torch.float32)\n",
    "    sr = sample[\"mp3\"][\"sampling_rate\"]                      # type: ignore[attr-defined]\n",
    "    ground_truth = sample[\"json\"]['text']                    # type: ignore[attr-defined]\n",
    "    \n",
    "    if sr != 16000:\n",
    "        audio_array = torchaudio.transforms.Resample(sr, 16000)(audio_array)\n",
    "    \n",
    "    # Process audio\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")  # type: ignore[attr-defined]\n",
    "    \n",
    "    seq_len = 1500  # typical for 30s audio\n",
    "    attn_mask = torch.full((1, 1, seq_len, seq_len), float('-inf'))\n",
    "    torch.diagonal(attn_mask[0, 0]).fill_(0.0)  # allow only self-attention\n",
    "    \n",
    "    # Generate transcription\n",
    "    with torch.no_grad():\n",
    "        latents = model.model.encoder(inputs.input_features, attention_mask=attn_mask)\n",
    "        predicted_ids = model.model.decoder(latents)\n",
    "    \n",
    "    # Decode transcription\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]  # type: ignore[attr-defined]\n",
    "\n",
    "    print(f\"Ground truth: {ground_truth}\")\n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0281e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
